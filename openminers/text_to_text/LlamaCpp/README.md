Install llama.cpp (make)
https://github.com/ggerganov/llama.cpp#usage

Install llama-cpp-python with CUDA support
https://github.com/oobabooga/text-generation-webui/blob/main/docs/llama.cpp-models.md#gpu-acceleration


> MUST HAVE CUDA and nvcc (nvidia-container-toolkit) installed!